{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Завантаження набору даних Iris:\n"
      ],
      "metadata": {
        "id": "YCiSo7J9oZt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PDV1kGZRoRdf"
      },
      "outputs": [],
      "source": [
        "# Імпортуємо необхідну функцію\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Завантажуємо дані\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target  # X - ознаки, y - цільові значення (класи)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Розподіл даних на навчальні та тестові набори:"
      ],
      "metadata": {
        "id": "_uvMzrIOonk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпортуємо функцію для розподілу даних\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Розподіляємо дані на навчальні та тестові\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B4g1VARloqDm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Використати вибірку ознак окремо для кожного класа."
      ],
      "metadata": {
        "id": "bJiYyCBjo5Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Вибірка ознак для кожного класу\n",
        "X_train_class_0 = X_train[y_train == 0]\n",
        "X_train_class_1 = X_train[y_train == 1]\n",
        "X_train_class_2 = X_train[y_train == 2]\n",
        "\n",
        "# Перевіримо розміри отриманих підвибірок\n",
        "print(\"Розмір вибірки класу 0:\", X_train_class_0.shape)\n",
        "print(\"Розмір вибірки класу 1:\", X_train_class_1.shape)\n",
        "print(\"Розмір вибірки класу 2:\", X_train_class_2.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0wiGJ4_o6a6",
        "outputId": "fb5533f4-3fda-4e28-a7f7-ac969538a9a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір вибірки класу 0: (31, 4)\n",
            "Розмір вибірки класу 1: (37, 4)\n",
            "Розмір вибірки класу 2: (37, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Реалізувати розрахунок матриць коваріації для набору ознак кожного класа."
      ],
      "metadata": {
        "id": "gFp9hWcvpIw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Обчислення коваріаційної матриці для кожного класу\n",
        "cov_class_0 = np.cov(X_train_class_0, rowvar=False)\n",
        "cov_class_1 = np.cov(X_train_class_1, rowvar=False)\n",
        "cov_class_2 = np.cov(X_train_class_2, rowvar=False)\n",
        "\n",
        "# Виведемо отримані коваріаційні матриці\n",
        "print(\"Коваріаційна матриця для класу 0:\\n\", cov_class_0)\n",
        "print(\"\\nКоваріаційна матриця для класу 1:\\n\", cov_class_1)\n",
        "print(\"\\nКоваріаційна матриця для класу 2:\\n\", cov_class_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW5zGnv_pKea",
        "outputId": "6158b963-6719-473d-db63-486ae38dfab3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коваріаційна матриця для класу 0:\n",
            " [[0.11569892 0.09817204 0.01669892 0.00677419]\n",
            " [0.09817204 0.14113978 0.01950538 0.00712903]\n",
            " [0.01669892 0.01950538 0.03436559 0.00877419]\n",
            " [0.00677419 0.00712903 0.00877419 0.01191398]]\n",
            "\n",
            "Коваріаційна матриця для класу 1:\n",
            " [[0.28297297 0.08816817 0.19847598 0.05760511]\n",
            " [0.08816817 0.08966967 0.09222973 0.04215465]\n",
            " [0.19847598 0.09222973 0.24599099 0.08385886]\n",
            " [0.05760511 0.04215465 0.08385886 0.04249249]]\n",
            "\n",
            "Коваріаційна матриця для класу 2:\n",
            " [[0.43414414 0.09777027 0.31913664 0.04939189]\n",
            " [0.09777027 0.09897898 0.08758258 0.06146396]\n",
            " [0.31913664 0.08758258 0.29644144 0.05224474]\n",
            " [0.04939189 0.06146396 0.05224474 0.0883033 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Реалізувати розрахунок обернених матриць коваріації."
      ],
      "metadata": {
        "id": "kBgWFcFHpSAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import inv\n",
        "\n",
        "# Обчислення обернених коваріаційних матриць для кожного класу\n",
        "inv_cov_class_0 = inv(cov_class_0)\n",
        "inv_cov_class_1 = inv(cov_class_1)\n",
        "inv_cov_class_2 = inv(cov_class_2)\n",
        "\n",
        "# Виведемо обернені матриці\n",
        "print(\"Обернена коваріаційна матриця для класу 0:\\n\", inv_cov_class_0)\n",
        "print(\"\\nОбернена коваріаційна матриця для класу 1:\\n\", inv_cov_class_1)\n",
        "print(\"\\nОбернена коваріаційна матриця для класу 2:\\n\", inv_cov_class_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrcsKHVkpTaE",
        "outputId": "ff77cb2c-0e77-4b29-fc40-abb00f2cfeb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обернена коваріаційна матриця для класу 0:\n",
            " [[ 21.28078227 -14.47324375  -1.53671066  -2.30792087]\n",
            " [-14.47324375  17.55993532  -2.89700961  -0.14452501]\n",
            " [ -1.53671066  -2.89700961  37.96238172 -25.35059422]\n",
            " [ -2.30792087  -0.14452501 -25.35059422 104.00351544]]\n",
            "\n",
            "Обернена коваріаційна матриця для класу 1:\n",
            " [[  9.46151636  -4.34355628  -9.47888632  10.18904836]\n",
            " [ -4.34355628  23.34535852   1.95432496 -21.12824922]\n",
            " [ -9.47888632   1.95432496  22.18845939 -32.87758504]\n",
            " [ 10.18904836 -21.12824922 -32.87758504  95.56487212]]\n",
            "\n",
            "Обернена коваріаційна матриця для класу 2:\n",
            " [[ 11.26427134  -1.81674205 -11.94821837   2.03313023]\n",
            " [ -1.81674205  21.88311083  -2.23739215 -12.89191212]\n",
            " [-11.94821837  -2.23739215  17.24300108  -1.96133194]\n",
            " [  2.03313023 -12.89191212  -1.96133194  20.32129143]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Обчислити апріорні імовірності кожного класа у тренувальних даних."
      ],
      "metadata": {
        "id": "2wvvVZPupacU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Кількість елементів у кожному класі\n",
        "n_class_0 = X_train_class_0.shape[0]\n",
        "n_class_1 = X_train_class_1.shape[0]\n",
        "n_class_2 = X_train_class_2.shape[0]\n",
        "\n",
        "# Загальна кількість елементів у тренувальній вибірці\n",
        "n_total = X_train.shape[0]\n",
        "\n",
        "# Обчислення апріорних ймовірностей\n",
        "prior_class_0 = n_class_0 / n_total\n",
        "prior_class_1 = n_class_1 / n_total\n",
        "prior_class_2 = n_class_2 / n_total\n",
        "\n",
        "# Виведемо апріорні ймовірності\n",
        "print(\"Апріорна ймовірність класу 0:\", prior_class_0)\n",
        "print(\"Апріорна ймовірність класу 1:\", prior_class_1)\n",
        "print(\"Апріорна ймовірність класу 2:\", prior_class_2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSonfPGJpbtp",
        "outputId": "ab84610b-0b67-47d2-e4ce-667ca0d6a473"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Апріорна ймовірність класу 0: 0.29523809523809524\n",
            "Апріорна ймовірність класу 1: 0.3523809523809524\n",
            "Апріорна ймовірність класу 2: 0.3523809523809524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Реалізувати функцію обчислення значень дискримінантної функції для одного рядка (вектора) тестових даних."
      ],
      "metadata": {
        "id": "Qxxy-eJCplU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv, det\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Завантажуємо набір даних Iris\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Розподіл на навчальні та тестові дані\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Вибірка ознак для кожного класу\n",
        "X_train_class_0 = X_train[y_train == 0]\n",
        "X_train_class_1 = X_train[y_train == 1]\n",
        "X_train_class_2 = X_train[y_train == 2]\n",
        "\n",
        "# Обчислення середнього значення та коваріаційної матриці для кожного класу\n",
        "mean_class_0 = np.mean(X_train_class_0, axis=0)\n",
        "cov_class_0 = np.cov(X_train_class_0, rowvar=False)\n",
        "\n",
        "mean_class_1 = np.mean(X_train_class_1, axis=0)\n",
        "cov_class_1 = np.cov(X_train_class_1, rowvar=False)\n",
        "\n",
        "mean_class_2 = np.mean(X_train_class_2, axis=0)\n",
        "cov_class_2 = np.cov(X_train_class_2, rowvar=False)\n",
        "\n",
        "# Обчислення обернених коваріаційних матриць\n",
        "inv_cov_class_0 = inv(cov_class_0)\n",
        "inv_cov_class_1 = inv(cov_class_1)\n",
        "inv_cov_class_2 = inv(cov_class_2)\n",
        "\n",
        "# Обчислення апріорних ймовірностей\n",
        "n_total = X_train.shape[0]\n",
        "prior_class_0 = X_train_class_0.shape[0] / n_total\n",
        "prior_class_1 = X_train_class_1.shape[0] / n_total\n",
        "prior_class_2 = X_train_class_2.shape[0] / n_total\n",
        "\n",
        "# Функція для обчислення дискримінантної функції\n",
        "def discriminant_function(x, mean, inv_cov, prior, cov):\n",
        "    term_1 = -0.5 * np.log(det(cov))\n",
        "    term_2 = -0.5 * (x - mean).T @ inv_cov @ (x - mean)\n",
        "    term_3 = np.log(prior)\n",
        "    return term_1 + term_2 + term_3\n",
        "\n",
        "# Тестуємо функцію на одному векторі з тестових даних\n",
        "test_vector = X_test[0]\n",
        "discriminant_class_0 = discriminant_function(test_vector, mean_class_0, inv_cov_class_0, prior_class_0, cov_class_0)\n",
        "discriminant_class_1 = discriminant_function(test_vector, mean_class_1, inv_cov_class_1, prior_class_1, cov_class_1)\n",
        "discriminant_class_2 = discriminant_function(test_vector, mean_class_2, inv_cov_class_2, prior_class_2, cov_class_2)\n",
        "\n",
        "print(\"Дискримінантна функція для класу 0:\", discriminant_class_0)\n",
        "print(\"Дискримінантна функція для класу 1:\", discriminant_class_1)\n",
        "print(\"Дискримінантна функція для класу 2:\", discriminant_class_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDJwQrhLpm1N",
        "outputId": "c84e7141-33f5-4bd0-90f4-15f5562d11ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дискримінантна функція для класу 0: -185.893067400142\n",
            "Дискримінантна функція для класу 1: 0.49829562348866774\n",
            "Дискримінантна функція для класу 2: -3.0769090367157554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Реалізувати функцію обчислення значень дискримінантної функції та імовірностей приналежності кожному класу для всієї матриці тестових даних."
      ],
      "metadata": {
        "id": "vJV7We40qwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_qda(X, means, inv_covs, priors, covs):\n",
        "    # Збережемо прогнозовані класи та значення дискримінантної функції для кожного класу\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    # Для кожного вектора у тестових даних\n",
        "    for x in X:\n",
        "        # Обчислимо значення дискримінантної функції для кожного класу\n",
        "        discriminants = [\n",
        "            discriminant_function(x, means[0], inv_covs[0], priors[0], covs[0]),\n",
        "            discriminant_function(x, means[1], inv_covs[1], priors[1], covs[1]),\n",
        "            discriminant_function(x, means[2], inv_covs[2], priors[2], covs[2])\n",
        "        ]\n",
        "\n",
        "        # Прогнозований клас - той, що має найбільше значення дискримінантної функції\n",
        "        predicted_class = np.argmax(discriminants)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "        # Ймовірність приналежності до кожного класу через softmax\n",
        "        exp_discriminants = np.exp(discriminants - np.max(discriminants))  # для числової стабільності\n",
        "        class_probabilities = exp_discriminants / np.sum(exp_discriminants)\n",
        "        probabilities.append(class_probabilities)\n",
        "\n",
        "    return predictions, probabilities\n",
        "\n",
        "# Визначимо параметри для кожного класу\n",
        "means = [mean_class_0, mean_class_1, mean_class_2]\n",
        "inv_covs = [inv_cov_class_0, inv_cov_class_1, inv_cov_class_2]\n",
        "priors = [prior_class_0, prior_class_1, prior_class_2]\n",
        "covs = [cov_class_0, cov_class_1, cov_class_2]\n",
        "\n",
        "# Отримуємо передбачені класи та ймовірності для всієї тестової вибірки\n",
        "predicted_classes, predicted_probabilities = predict_qda(X_test, means, inv_covs, priors, covs)\n",
        "\n",
        "# Виведемо перші 5 результатів для прикладу\n",
        "for i in range(5):\n",
        "    print(f\"Тестовий вектор {i + 1}: Прогнозований клас = {predicted_classes[i]}, Ймовірності = {predicted_probabilities[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L97rVUxmqx_V",
        "outputId": "322c9cb5-3e8b-4052-ca08-034d442db55c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тестовий вектор 1: Прогнозований клас = 1, Ймовірності = [1.09461742e-81 9.72753474e-01 2.72465259e-02]\n",
            "Тестовий вектор 2: Прогнозований клас = 0, Ймовірності = [1.00000000e+00 5.73230921e-28 3.05634855e-63]\n",
            "Тестовий вектор 3: Прогнозований клас = 2, Ймовірності = [2.43687730e-251 4.97846558e-009 9.99999995e-001]\n",
            "Тестовий вектор 4: Прогнозований клас = 1, Ймовірності = [5.10831398e-77 9.97298384e-01 2.70161647e-03]\n",
            "Тестовий вектор 5: Прогнозований клас = 1, Ймовірності = [1.26234369e-98 9.99396589e-01 6.03410624e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Виконати прогнозування на тестових даних за допомогою функії QuadraticDiscriminantAnalysis() бібліотеки sklearn та порівняти отримані результати."
      ],
      "metadata": {
        "id": "j-8_Wu7ZrCAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Ініціалізуємо модель QDA\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Навчаємо модель на тренувальних даних\n",
        "qda.fit(X_train, y_train)\n",
        "\n",
        "# Виконуємо прогнозування на тестових даних\n",
        "qda_predictions = qda.predict(X_test)\n",
        "\n",
        "# Порівнюємо точність із нашою реалізацією\n",
        "custom_accuracy = accuracy_score(y_test, predicted_classes)\n",
        "qda_accuracy = accuracy_score(y_test, qda_predictions)\n",
        "\n",
        "print(\"Точність нашої реалізації QDA:\", custom_accuracy)\n",
        "print(\"Точність реалізації QDA з sklearn:\", qda_accuracy)\n",
        "\n",
        "# Детальний звіт по класифікації для порівняння результатів\n",
        "print(\"\\nЗвіт нашої реалізації QDA:\\n\", classification_report(y_test, predicted_classes))\n",
        "print(\"\\nЗвіт QDA з sklearn:\\n\", classification_report(y_test, qda_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_eM7rSrEFh",
        "outputId": "bb5dfdef-c95c-4c5a-81d2-ab86336d3b66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точність нашої реалізації QDA: 1.0\n",
            "Точність реалізації QDA з sklearn: 1.0\n",
            "\n",
            "Звіт нашої реалізації QDA:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "Звіт QDA з sklearn:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Зробити висновок про ступінь схожості результатів, отриманих власною функцією та бібліотекою sklearn."
      ],
      "metadata": {
        "id": "7sPUOpC4rbGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результати, отримані за допомогою власної реалізації методу QDA, та результати, отримані за допомогою бібліотеки sklearn, є повністю ідентичними. Обидва підходи показали 100% точність на тестових даних, що підтверджується значеннями метрик precision, recall та f1-score, які дорівнюють 1.00 для кожного класу. Це свідчить про те, що власна реалізація методу правильно враховує всі необхідні математичні операції, такі як обчислення середніх значень, коваріаційних матриць, їх обернених, а також обчислення дискримінантних функцій.\n",
        "\n",
        "Ступінь схожості: обидві реалізації показують абсолютно однакові результати, що вказує на високу ступінь схожості. Це означає, що власна реалізація може бути використана як альтернативний підхід до QDA, хоча бібліотечне рішення є більш зручним і оптимізованим для практичного використання.\n",
        "\n",
        "Таким чином, ми можемо зробити висновок, що власна реалізація QDA є коректною та підтверджує теоретичні основи методу."
      ],
      "metadata": {
        "id": "sfs_mjwFrd_-"
      }
    }
  ]
}