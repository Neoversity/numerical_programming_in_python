# -*- coding: utf-8 -*-
"""hw_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wUm5Aq38Ec_m56KPVJ1GZmjETcSSbDKY

## 1. Завантаження набору даних Iris:
"""

# Імпортуємо необхідну функцію
from sklearn.datasets import load_iris

# Завантажуємо дані
data = load_iris()
X, y = data.data, data.target  # X - ознаки, y - цільові значення (класи)

"""## 2. Розподіл даних на навчальні та тестові набори:"""

# Імпортуємо функцію для розподілу даних
from sklearn.model_selection import train_test_split

# Розподіляємо дані на навчальні та тестові
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""## 3. Використати вибірку ознак окремо для кожного класа."""

import numpy as np

# Вибірка ознак для кожного класу
X_train_class_0 = X_train[y_train == 0]
X_train_class_1 = X_train[y_train == 1]
X_train_class_2 = X_train[y_train == 2]

# Перевіримо розміри отриманих підвибірок
print("Розмір вибірки класу 0:", X_train_class_0.shape)
print("Розмір вибірки класу 1:", X_train_class_1.shape)
print("Розмір вибірки класу 2:", X_train_class_2.shape)

"""## 4. Реалізувати розрахунок матриць коваріації для набору ознак кожного класа."""

import numpy as np

# Обчислення коваріаційної матриці для кожного класу
cov_class_0 = np.cov(X_train_class_0, rowvar=False)
cov_class_1 = np.cov(X_train_class_1, rowvar=False)
cov_class_2 = np.cov(X_train_class_2, rowvar=False)

# Виведемо отримані коваріаційні матриці
print("Коваріаційна матриця для класу 0:\n", cov_class_0)
print("\nКоваріаційна матриця для класу 1:\n", cov_class_1)
print("\nКоваріаційна матриця для класу 2:\n", cov_class_2)

"""## 5. Реалізувати розрахунок обернених матриць коваріації."""

from numpy.linalg import inv

# Обчислення обернених коваріаційних матриць для кожного класу
inv_cov_class_0 = inv(cov_class_0)
inv_cov_class_1 = inv(cov_class_1)
inv_cov_class_2 = inv(cov_class_2)

# Виведемо обернені матриці
print("Обернена коваріаційна матриця для класу 0:\n", inv_cov_class_0)
print("\nОбернена коваріаційна матриця для класу 1:\n", inv_cov_class_1)
print("\nОбернена коваріаційна матриця для класу 2:\n", inv_cov_class_2)

"""## 6. Обчислити апріорні імовірності кожного класа у тренувальних даних."""

# Кількість елементів у кожному класі
n_class_0 = X_train_class_0.shape[0]
n_class_1 = X_train_class_1.shape[0]
n_class_2 = X_train_class_2.shape[0]

# Загальна кількість елементів у тренувальній вибірці
n_total = X_train.shape[0]

# Обчислення апріорних ймовірностей
prior_class_0 = n_class_0 / n_total
prior_class_1 = n_class_1 / n_total
prior_class_2 = n_class_2 / n_total

# Виведемо апріорні ймовірності
print("Апріорна ймовірність класу 0:", prior_class_0)
print("Апріорна ймовірність класу 1:", prior_class_1)
print("Апріорна ймовірність класу 2:", prior_class_2)

"""## 7. Реалізувати функцію обчислення значень дискримінантної функції для одного рядка (вектора) тестових даних."""

import numpy as np
from numpy.linalg import inv, det
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Завантажуємо набір даних Iris
data = load_iris()
X, y = data.data, data.target

# Розподіл на навчальні та тестові дані
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Вибірка ознак для кожного класу
X_train_class_0 = X_train[y_train == 0]
X_train_class_1 = X_train[y_train == 1]
X_train_class_2 = X_train[y_train == 2]

# Обчислення середнього значення та коваріаційної матриці для кожного класу
mean_class_0 = np.mean(X_train_class_0, axis=0)
cov_class_0 = np.cov(X_train_class_0, rowvar=False)

mean_class_1 = np.mean(X_train_class_1, axis=0)
cov_class_1 = np.cov(X_train_class_1, rowvar=False)

mean_class_2 = np.mean(X_train_class_2, axis=0)
cov_class_2 = np.cov(X_train_class_2, rowvar=False)

# Обчислення обернених коваріаційних матриць
inv_cov_class_0 = inv(cov_class_0)
inv_cov_class_1 = inv(cov_class_1)
inv_cov_class_2 = inv(cov_class_2)

# Обчислення апріорних ймовірностей
n_total = X_train.shape[0]
prior_class_0 = X_train_class_0.shape[0] / n_total
prior_class_1 = X_train_class_1.shape[0] / n_total
prior_class_2 = X_train_class_2.shape[0] / n_total

# Функція для обчислення дискримінантної функції
def discriminant_function(x, mean, inv_cov, prior, cov):
    term_1 = -0.5 * np.log(det(cov))
    term_2 = -0.5 * (x - mean).T @ inv_cov @ (x - mean)
    term_3 = np.log(prior)
    return term_1 + term_2 + term_3

# Тестуємо функцію на одному векторі з тестових даних
test_vector = X_test[0]
discriminant_class_0 = discriminant_function(test_vector, mean_class_0, inv_cov_class_0, prior_class_0, cov_class_0)
discriminant_class_1 = discriminant_function(test_vector, mean_class_1, inv_cov_class_1, prior_class_1, cov_class_1)
discriminant_class_2 = discriminant_function(test_vector, mean_class_2, inv_cov_class_2, prior_class_2, cov_class_2)

print("Дискримінантна функція для класу 0:", discriminant_class_0)
print("Дискримінантна функція для класу 1:", discriminant_class_1)
print("Дискримінантна функція для класу 2:", discriminant_class_2)

"""## 8. Реалізувати функцію обчислення значень дискримінантної функції та імовірностей приналежності кожному класу для всієї матриці тестових даних."""

def predict_qda(X, means, inv_covs, priors, covs):
    # Збережемо прогнозовані класи та значення дискримінантної функції для кожного класу
    predictions = []
    probabilities = []

    # Для кожного вектора у тестових даних
    for x in X:
        # Обчислимо значення дискримінантної функції для кожного класу
        discriminants = [
            discriminant_function(x, means[0], inv_covs[0], priors[0], covs[0]),
            discriminant_function(x, means[1], inv_covs[1], priors[1], covs[1]),
            discriminant_function(x, means[2], inv_covs[2], priors[2], covs[2])
        ]

        # Прогнозований клас - той, що має найбільше значення дискримінантної функції
        predicted_class = np.argmax(discriminants)
        predictions.append(predicted_class)

        # Ймовірність приналежності до кожного класу через softmax
        exp_discriminants = np.exp(discriminants - np.max(discriminants))  # для числової стабільності
        class_probabilities = exp_discriminants / np.sum(exp_discriminants)
        probabilities.append(class_probabilities)

    return predictions, probabilities

# Визначимо параметри для кожного класу
means = [mean_class_0, mean_class_1, mean_class_2]
inv_covs = [inv_cov_class_0, inv_cov_class_1, inv_cov_class_2]
priors = [prior_class_0, prior_class_1, prior_class_2]
covs = [cov_class_0, cov_class_1, cov_class_2]

# Отримуємо передбачені класи та ймовірності для всієї тестової вибірки
predicted_classes, predicted_probabilities = predict_qda(X_test, means, inv_covs, priors, covs)

# Виведемо перші 5 результатів для прикладу
for i in range(5):
    print(f"Тестовий вектор {i + 1}: Прогнозований клас = {predicted_classes[i]}, Ймовірності = {predicted_probabilities[i]}")

"""## 9. Виконати прогнозування на тестових даних за допомогою функії QuadraticDiscriminantAnalysis() бібліотеки sklearn та порівняти отримані результати."""

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import accuracy_score, classification_report

# Ініціалізуємо модель QDA
qda = QuadraticDiscriminantAnalysis()

# Навчаємо модель на тренувальних даних
qda.fit(X_train, y_train)

# Виконуємо прогнозування на тестових даних
qda_predictions = qda.predict(X_test)

# Порівнюємо точність із нашою реалізацією
custom_accuracy = accuracy_score(y_test, predicted_classes)
qda_accuracy = accuracy_score(y_test, qda_predictions)

print("Точність нашої реалізації QDA:", custom_accuracy)
print("Точність реалізації QDA з sklearn:", qda_accuracy)

# Детальний звіт по класифікації для порівняння результатів
print("\nЗвіт нашої реалізації QDA:\n", classification_report(y_test, predicted_classes))
print("\nЗвіт QDA з sklearn:\n", classification_report(y_test, qda_predictions))

"""## 10. Зробити висновок про ступінь схожості результатів, отриманих власною функцією та бібліотекою sklearn.

Результати, отримані за допомогою власної реалізації методу QDA, та результати, отримані за допомогою бібліотеки sklearn, є повністю ідентичними. Обидва підходи показали 100% точність на тестових даних, що підтверджується значеннями метрик precision, recall та f1-score, які дорівнюють 1.00 для кожного класу. Це свідчить про те, що власна реалізація методу правильно враховує всі необхідні математичні операції, такі як обчислення середніх значень, коваріаційних матриць, їх обернених, а також обчислення дискримінантних функцій.

Ступінь схожості: обидві реалізації показують абсолютно однакові результати, що вказує на високу ступінь схожості. Це означає, що власна реалізація може бути використана як альтернативний підхід до QDA, хоча бібліотечне рішення є більш зручним і оптимізованим для практичного використання.

Таким чином, ми можемо зробити висновок, що власна реалізація QDA є коректною та підтверджує теоретичні основи методу.
"""